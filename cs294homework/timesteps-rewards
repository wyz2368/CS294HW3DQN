yongzhao@yongzhao-Lenovo-ideapad-Y700-15ISK:~$ python '/home/yongzhao/Desktop/homework-master/hw3/run_dqn_atari.py' 
[2017-07-18 21:55:12,532] Making new env: PongNoFrameskip-v4
[2017-07-18 21:55:13,670] Creating monitor directory /tmp/hw3_vid_dir2/gym
2017-07-18 21:55:13.671076: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 21:55:13.671089: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 21:55:13.671114: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 21:55:13.671119: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 21:55:13.671124: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 21:55:14.888719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-07-18 21:55:14.889613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 960M
major: 5 minor: 0 memoryClockRate (GHz) 1.176
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 3.76GiB
2017-07-18 21:55:14.889673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-07-18 21:55:14.889696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-07-18 21:55:14.889738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)
2017-07-18 21:55:14.942606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)
('AVAILABLE GPUS: ', [u'device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0'])
[2017-07-18 21:55:15,457] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.2036.video000000.mp4
[2017-07-18 21:55:26,285] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.2036.video000001.mp4
[2017-07-18 21:55:33,943] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.2036.video000008.mp4
[2017-07-18 21:55:54,910] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.2036.video000027.mp4
[2017-07-18 21:57:23,671] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.2036.video000064.mp4
Timestep 60000
mean reward (100 episodes) -20.409091
best mean reward -inf
episodes 66
exploration 0.946000
learning_rate 0.000100
Timestep 70000
mean reward (100 episodes) -20.363636
best mean reward -inf
episodes 77
exploration 0.937000
learning_rate 0.000100
Timestep 80000
mean reward (100 episodes) -20.333333
best mean reward -inf
episodes 87
exploration 0.928000
learning_rate 0.000100
Timestep 90000
mean reward (100 episodes) -20.373737
best mean reward -inf
episodes 99
exploration 0.919000
learning_rate 0.000100
Timestep 100000
mean reward (100 episodes) -20.320000
best mean reward -20.320000
episodes 109
exploration 0.910000
learning_rate 0.000100
Timestep 110000
mean reward (100 episodes) -20.300000
best mean reward -20.290000
episodes 120
exploration 0.901000
learning_rate 0.000100
[2017-07-18 22:03:42,379] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.2036.video000125.mp4
Timestep 120000
mean reward (100 episodes) -20.290000
best mean reward -20.280000
episodes 131
exploration 0.892000
learning_rate 0.000100
Timestep 130000
mean reward (100 episodes) -20.270000
best mean reward -20.270000
episodes 142
exploration 0.883000
learning_rate 0.000100
Timestep 140000
mean reward (100 episodes) -20.260000
best mean reward -20.240000
episodes 153
exploration 0.874000
learning_rate 0.000100
Timestep 150000
mean reward (100 episodes) -20.260000
best mean reward -20.240000
episodes 164
exploration 0.865000
learning_rate 0.000100
Timestep 160000
mean reward (100 episodes) -20.290000
best mean reward -20.240000
episodes 174
exploration 0.856000
learning_rate 0.000100
Timestep 170000
mean reward (100 episodes) -20.240000
best mean reward -20.240000
episodes 184
exploration 0.847000
learning_rate 0.000100
Timestep 180000
mean reward (100 episodes) -20.140000
best mean reward -20.140000
episodes 194
exploration 0.838000
learning_rate 0.000100
Timestep 190000
mean reward (100 episodes) -20.070000
best mean reward -20.050000
episodes 203
exploration 0.829000
learning_rate 0.000100
Timestep 200000
mean reward (100 episodes) -20.030000
best mean reward -20.020000
episodes 213
exploration 0.820000
learning_rate 0.000100
[2017-07-18 22:13:40,466] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.2036.video000216.mp4
Timestep 210000
mean reward (100 episodes) -20.000000
best mean reward -20.000000
episodes 222
exploration 0.811000
learning_rate 0.000100
Timestep 220000
mean reward (100 episodes) -19.920000
best mean reward -19.920000
episodes 231
exploration 0.802000
learning_rate 0.000100
Timestep 230000
mean reward (100 episodes) -19.790000
best mean reward -19.790000
episodes 240
exploration 0.793000
learning_rate 0.000100
Timestep 240000
mean reward (100 episodes) -19.710000
best mean reward -19.710000
episodes 249
exploration 0.784000
learning_rate 0.000100
Timestep 250000
mean reward (100 episodes) -19.670000
best mean reward -19.640000
episodes 257
exploration 0.775000
learning_rate 0.000100
Timestep 260000
mean reward (100 episodes) -19.590000
best mean reward -19.590000
episodes 266
exploration 0.766000
learning_rate 0.000100
Timestep 270000
mean reward (100 episodes) -19.470000
best mean reward -19.470000
episodes 275
exploration 0.757000
learning_rate 0.000100
Timestep 280000
mean reward (100 episodes) -19.500000
best mean reward -19.470000
episodes 284
exploration 0.748000
learning_rate 0.000100
Timestep 290000
mean reward (100 episodes) -19.510000
best mean reward -19.470000
episodes 292
exploration 0.739000
learning_rate 0.000100
Timestep 300000
mean reward (100 episodes) -19.490000
best mean reward -19.470000
episodes 300
exploration 0.730000
learning_rate 0.000100
Timestep 310000
mean reward (100 episodes) -19.500000
best mean reward -19.460000
episodes 309
exploration 0.721000
learning_rate 0.000100
Timestep 320000
mean reward (100 episodes) -19.470000
best mean reward -19.460000
episodes 318
exploration 0.712000
learning_rate 0.000100
Timestep 330000
mean reward (100 episodes) -19.300000
best mean reward -19.300000
episodes 326
exploration 0.703000
learning_rate 0.000100
Timestep 340000
mean reward (100 episodes) -19.320000
best mean reward -19.290000
episodes 334
exploration 0.694000
learning_rate 0.000100
Timestep 350000
mean reward (100 episodes) -19.230000
best mean reward -19.220000
episodes 342
exploration 0.685000
learning_rate 0.000100
[2017-07-18 22:30:56,219] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.2036.video000343.mp4
Timestep 360000
mean reward (100 episodes) -19.140000
best mean reward -19.140000
episodes 351
exploration 0.676000
learning_rate 0.000100
Timestep 370000
mean reward (100 episodes) -19.150000
best mean reward -19.100000
episodes 359
exploration 0.667000
learning_rate 0.000100
Timestep 380000
mean reward (100 episodes) -19.160000
best mean reward -19.100000
episodes 368
exploration 0.658000
learning_rate 0.000100
Timestep 390000
mean reward (100 episodes) -19.180000
best mean reward -19.100000
episodes 376
exploration 0.649000
learning_rate 0.000100
Timestep 400000
mean reward (100 episodes) -19.180000
best mean reward -19.100000
episodes 385
exploration 0.640000
learning_rate 0.000100
Timestep 410000
mean reward (100 episodes) -19.090000
best mean reward -19.090000
episodes 394
exploration 0.631000
learning_rate 0.000100
Timestep 420000
mean reward (100 episodes) -19.130000
best mean reward -19.070000
episodes 403
exploration 0.622000
learning_rate 0.000100
Timestep 430000
mean reward (100 episodes) -19.060000
best mean reward -19.060000
episodes 410
exploration 0.613000
learning_rate 0.000100
Timestep 440000
mean reward (100 episodes) -18.990000
best mean reward -18.980000
episodes 417
exploration 0.604000
learning_rate 0.000100
Timestep 450000
mean reward (100 episodes) -19.000000
best mean reward -18.940000
episodes 425
exploration 0.595000
learning_rate 0.000100
Timestep 460000
mean reward (100 episodes) -19.020000
best mean reward -18.940000
episodes 433
exploration 0.586000
learning_rate 0.000100
Timestep 470000
mean reward (100 episodes) -19.140000
best mean reward -18.940000
episodes 442
exploration 0.577000
learning_rate 0.000100
^CTraceback (most recent call last):
  File "/home/yongzhao/Desktop/homework-master/hw3/run_dqn_atari.py", line 133, in <module>
    main()
  File "/home/yongzhao/Desktop/homework-master/hw3/run_dqn_atari.py", line 130, in main
    atari_learn(env, session, num_timesteps=task.max_timesteps)
  File "/home/yongzhao/Desktop/homework-master/hw3/run_dqn_atari.py", line 77, in atari_learn
    grad_norm_clipping=10
  File "/home/yongzhao/Desktop/homework-master/hw3/dqn.py", line 304, in learn
    learning_rate:optimizer_spec.lr_schedule.value(t)
  File "/home/yongzhao/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 789, in run
    run_metadata_ptr)
  File "/home/yongzhao/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 997, in _run
    feed_dict_string, options, run_metadata)
  File "/home/yongzhao/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1132, in _do_run
    target_list, options, run_metadata)
  File "/home/yongzhao/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1139, in _do_call
    return fn(*args)
  File "/home/yongzhao/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1121, in _run_fn
    status, run_metadata)
KeyboardInterrupt
[2017-07-18 22:46:01,425] Finished writing results. You can upload them to the scoreboard via gym.upload('/tmp/hw3_vid_dir2/gym')
yongzhao@yongzhao-Lenovo-ideapad-Y700-15ISK:~$ python '/home/yongzhao/Desktop/homework-master/hw3/run_dqn_atari.py' 
[2017-07-18 22:47:39,282] Making new env: PongNoFrameskip-v4
[2017-07-18 22:47:39,599] Clearing 18 monitor files from previous run (because force=True was provided)
2017-07-18 22:47:39.600349: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 22:47:39.600360: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 22:47:39.600382: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 22:47:39.600387: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 22:47:39.600399: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-18 22:47:39.695691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-07-18 22:47:39.696047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 960M
major: 5 minor: 0 memoryClockRate (GHz) 1.176
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 3.72GiB
2017-07-18 22:47:39.696078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-07-18 22:47:39.696083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-07-18 22:47:39.696111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)
2017-07-18 22:47:39.710855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)
('AVAILABLE GPUS: ', [u'device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0'])
[2017-07-18 22:47:39,980] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000000.mp4
[2017-07-18 22:47:42,044] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000001.mp4
[2017-07-18 22:47:49,415] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000008.mp4
[2017-07-18 22:48:08,267] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000027.mp4
[2017-07-18 22:49:18,650] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000064.mp4
Timestep 60000
mean reward (100 episodes) -20.492537
best mean reward -inf
episodes 67
exploration 0.946000
learning_rate 0.000100
Timestep 70000
mean reward (100 episodes) -20.500000
best mean reward -inf
episodes 78
exploration 0.937000
learning_rate 0.000100
Timestep 80000
mean reward (100 episodes) -20.471910
best mean reward -inf
episodes 89
exploration 0.928000
learning_rate 0.000100
Timestep 90000
mean reward (100 episodes) -20.454545
best mean reward -inf
episodes 99
exploration 0.919000
learning_rate 0.000100
Timestep 100000
mean reward (100 episodes) -20.470000
best mean reward -20.460000
episodes 110
exploration 0.910000
learning_rate 0.000100
Timestep 110000
mean reward (100 episodes) -20.470000
best mean reward -20.450000
episodes 121
exploration 0.901000
learning_rate 0.000100
[2017-07-18 22:55:02,444] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000125.mp4
Timestep 120000
mean reward (100 episodes) -20.470000
best mean reward -20.450000
episodes 131
exploration 0.892000
learning_rate 0.000100
Timestep 130000
mean reward (100 episodes) -20.430000
best mean reward -20.430000
episodes 142
exploration 0.883000
learning_rate 0.000100
Timestep 140000
mean reward (100 episodes) -20.420000
best mean reward -20.400000
episodes 152
exploration 0.874000
learning_rate 0.000100
Timestep 150000
mean reward (100 episodes) -20.400000
best mean reward -20.380000
episodes 163
exploration 0.865000
learning_rate 0.000100
Timestep 160000
mean reward (100 episodes) -20.400000
best mean reward -20.380000
episodes 173
exploration 0.856000
learning_rate 0.000100
Timestep 170000
mean reward (100 episodes) -20.350000
best mean reward -20.340000
episodes 183
exploration 0.847000
learning_rate 0.000100
Timestep 180000
mean reward (100 episodes) -20.360000
best mean reward -20.340000
episodes 194
exploration 0.838000
learning_rate 0.000100
Timestep 190000
mean reward (100 episodes) -20.350000
best mean reward -20.340000
episodes 205
exploration 0.829000
learning_rate 0.000100
Timestep 200000
mean reward (100 episodes) -20.300000
best mean reward -20.300000
episodes 215
exploration 0.820000
learning_rate 0.000100
[2017-07-18 23:03:59,917] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000216.mp4
Timestep 210000
mean reward (100 episodes) -20.320000
best mean reward -20.290000
episodes 224
exploration 0.811000
learning_rate 0.000100
Timestep 220000
mean reward (100 episodes) -20.230000
best mean reward -20.230000
episodes 234
exploration 0.802000
learning_rate 0.000100
Timestep 230000
mean reward (100 episodes) -20.190000
best mean reward -20.190000
episodes 244
exploration 0.793000
learning_rate 0.000100
Timestep 240000
mean reward (100 episodes) -20.170000
best mean reward -20.170000
episodes 253
exploration 0.784000
learning_rate 0.000100
Timestep 250000
mean reward (100 episodes) -20.140000
best mean reward -20.140000
episodes 263
exploration 0.775000
learning_rate 0.000100
Timestep 260000
mean reward (100 episodes) -20.020000
best mean reward -20.010000
episodes 272
exploration 0.766000
learning_rate 0.000100
Timestep 270000
mean reward (100 episodes) -19.950000
best mean reward -19.950000
episodes 280
exploration 0.757000
learning_rate 0.000100
Timestep 280000
mean reward (100 episodes) -19.870000
best mean reward -19.870000
episodes 289
exploration 0.748000
learning_rate 0.000100
Timestep 290000
mean reward (100 episodes) -19.770000
best mean reward -19.770000
episodes 298
exploration 0.739000
learning_rate 0.000100
Timestep 300000
mean reward (100 episodes) -19.690000
best mean reward -19.690000
episodes 306
exploration 0.730000
learning_rate 0.000100
Timestep 310000
mean reward (100 episodes) -19.600000
best mean reward -19.600000
episodes 314
exploration 0.721000
learning_rate 0.000100
Timestep 320000
mean reward (100 episodes) -19.560000
best mean reward -19.560000
episodes 322
exploration 0.712000
learning_rate 0.000100
Timestep 330000
mean reward (100 episodes) -19.480000
best mean reward -19.480000
episodes 331
exploration 0.703000
learning_rate 0.000100
Timestep 340000
mean reward (100 episodes) -19.320000
best mean reward -19.320000
episodes 338
exploration 0.694000
learning_rate 0.000100
[2017-07-18 23:19:12,420] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000343.mp4
Timestep 350000
mean reward (100 episodes) -19.310000
best mean reward -19.300000
episodes 346
exploration 0.685000
learning_rate 0.000100
Timestep 360000
mean reward (100 episodes) -19.210000
best mean reward -19.200000
episodes 354
exploration 0.676000
learning_rate 0.000100
Timestep 370000
mean reward (100 episodes) -19.170000
best mean reward -19.150000
episodes 363
exploration 0.667000
learning_rate 0.000100
Timestep 380000
mean reward (100 episodes) -19.130000
best mean reward -19.110000
episodes 371
exploration 0.658000
learning_rate 0.000100
Timestep 390000
mean reward (100 episodes) -19.140000
best mean reward -19.090000
episodes 380
exploration 0.649000
learning_rate 0.000100
Timestep 400000
mean reward (100 episodes) -19.190000
best mean reward -19.090000
episodes 389
exploration 0.640000
learning_rate 0.000100
Timestep 410000
mean reward (100 episodes) -19.230000
best mean reward -19.090000
episodes 397
exploration 0.631000
learning_rate 0.000100
Timestep 420000
mean reward (100 episodes) -19.210000
best mean reward -19.090000
episodes 405
exploration 0.622000
learning_rate 0.000100
Timestep 430000
mean reward (100 episodes) -19.190000
best mean reward -19.090000
episodes 413
exploration 0.613000
learning_rate 0.000100
Timestep 440000
mean reward (100 episodes) -19.150000
best mean reward -19.090000
episodes 421
exploration 0.604000
learning_rate 0.000100
Timestep 450000
mean reward (100 episodes) -19.150000
best mean reward -19.090000
episodes 430
exploration 0.595000
learning_rate 0.000100
Timestep 460000
mean reward (100 episodes) -19.210000
best mean reward -19.090000
episodes 437
exploration 0.586000
learning_rate 0.000100
Timestep 470000
mean reward (100 episodes) -19.220000
best mean reward -19.090000
episodes 445
exploration 0.577000
learning_rate 0.000100
Timestep 480000
mean reward (100 episodes) -19.160000
best mean reward -19.090000
episodes 452
exploration 0.568000
learning_rate 0.000100
Timestep 490000
mean reward (100 episodes) -19.050000
best mean reward -19.020000
episodes 460
exploration 0.559000
learning_rate 0.000100
Timestep 500000
mean reward (100 episodes) -19.090000
best mean reward -18.990000
episodes 468
exploration 0.550000
learning_rate 0.000100
Timestep 510000
mean reward (100 episodes) -19.060000
best mean reward -18.990000
episodes 475
exploration 0.541000
learning_rate 0.000100
Timestep 520000
mean reward (100 episodes) -19.010000
best mean reward -18.990000
episodes 482
exploration 0.532000
learning_rate 0.000100
Timestep 530000
mean reward (100 episodes) -18.910000
best mean reward -18.910000
episodes 490
exploration 0.523000
learning_rate 0.000100
Timestep 540000
mean reward (100 episodes) -18.930000
best mean reward -18.880000
episodes 499
exploration 0.514000
learning_rate 0.000100
Timestep 550000
mean reward (100 episodes) -19.040000
best mean reward -18.880000
episodes 508
exploration 0.505000
learning_rate 0.000100
[2017-07-18 23:42:07,245] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000512.mp4
Timestep 560000
mean reward (100 episodes) -18.910000
best mean reward -18.880000
episodes 516
exploration 0.496000
learning_rate 0.000100
Timestep 570000
mean reward (100 episodes) -18.950000
best mean reward -18.880000
episodes 523
exploration 0.487000
learning_rate 0.000100
Timestep 580000
mean reward (100 episodes) -18.870000
best mean reward -18.870000
episodes 529
exploration 0.478000
learning_rate 0.000100
Timestep 590000
mean reward (100 episodes) -18.870000
best mean reward -18.830000
episodes 537
exploration 0.469000
learning_rate 0.000100
Timestep 600000
mean reward (100 episodes) -18.820000
best mean reward -18.820000
episodes 544
exploration 0.460000
learning_rate 0.000100
Timestep 610000
mean reward (100 episodes) -18.740000
best mean reward -18.740000
episodes 550
exploration 0.451000
learning_rate 0.000100
Timestep 620000
mean reward (100 episodes) -18.750000
best mean reward -18.740000
episodes 557
exploration 0.442000
learning_rate 0.000100
Timestep 630000
mean reward (100 episodes) -18.680000
best mean reward -18.670000
episodes 564
exploration 0.433000
learning_rate 0.000100
Timestep 640000
mean reward (100 episodes) -18.640000
best mean reward -18.610000
episodes 571
exploration 0.424000
learning_rate 0.000100
Timestep 650000
mean reward (100 episodes) -18.730000
best mean reward -18.610000
episodes 579
exploration 0.415000
learning_rate 0.000100
Timestep 660000
mean reward (100 episodes) -18.630000
best mean reward -18.610000
episodes 585
exploration 0.406000
learning_rate 0.000100
Timestep 670000
mean reward (100 episodes) -18.580000
best mean reward -18.560000
episodes 592
exploration 0.397000
learning_rate 0.000100
Timestep 680000
mean reward (100 episodes) -18.550000
best mean reward -18.530000
episodes 600
exploration 0.388000
learning_rate 0.000100
Timestep 690000
mean reward (100 episodes) -18.470000
best mean reward -18.470000
episodes 607
exploration 0.379000
learning_rate 0.000100
Timestep 700000
mean reward (100 episodes) -18.370000
best mean reward -18.370000
episodes 613
exploration 0.370000
learning_rate 0.000100
Timestep 710000
mean reward (100 episodes) -18.430000
best mean reward -18.370000
episodes 620
exploration 0.361000
learning_rate 0.000100
Timestep 720000
mean reward (100 episodes) -18.360000
best mean reward -18.360000
episodes 627
exploration 0.352000
learning_rate 0.000100
Timestep 730000
mean reward (100 episodes) -18.320000
best mean reward -18.320000
episodes 633
exploration 0.343000
learning_rate 0.000100
Timestep 740000
mean reward (100 episodes) -18.330000
best mean reward -18.300000
episodes 639
exploration 0.334000
learning_rate 0.000100
Timestep 750000
mean reward (100 episodes) -18.230000
best mean reward -18.230000
episodes 645
exploration 0.325000
learning_rate 0.000100
Timestep 760000
mean reward (100 episodes) -18.170000
best mean reward -18.170000
episodes 651
exploration 0.316000
learning_rate 0.000100
Timestep 770000
mean reward (100 episodes) -18.130000
best mean reward -18.080000
episodes 657
exploration 0.307000
learning_rate 0.000100
Timestep 780000
mean reward (100 episodes) -18.100000
best mean reward -18.080000
episodes 663
exploration 0.298000
learning_rate 0.000100
Timestep 790000
mean reward (100 episodes) -18.070000
best mean reward -18.070000
episodes 669
exploration 0.289000
learning_rate 0.000100
Timestep 800000
mean reward (100 episodes) -17.850000
best mean reward -17.850000
episodes 674
exploration 0.280000
learning_rate 0.000100
Timestep 810000
mean reward (100 episodes) -17.710000
best mean reward -17.710000
episodes 679
exploration 0.271000
learning_rate 0.000100
Timestep 820000
mean reward (100 episodes) -17.640000
best mean reward -17.620000
episodes 684
exploration 0.262000
learning_rate 0.000100
Timestep 830000
mean reward (100 episodes) -17.450000
best mean reward -17.450000
episodes 690
exploration 0.253000
learning_rate 0.000100
Timestep 840000
mean reward (100 episodes) -17.370000
best mean reward -17.370000
episodes 695
exploration 0.244000
learning_rate 0.000100
Timestep 850000
mean reward (100 episodes) -17.180000
best mean reward -17.180000
episodes 701
exploration 0.235000
learning_rate 0.000100
Timestep 860000
mean reward (100 episodes) -16.970000
best mean reward -16.970000
episodes 705
exploration 0.226000
learning_rate 0.000100
Timestep 870000
mean reward (100 episodes) -16.750000
best mean reward -16.750000
episodes 711
exploration 0.217000
learning_rate 0.000100
Timestep 880000
mean reward (100 episodes) -16.600000
best mean reward -16.600000
episodes 717
exploration 0.208000
learning_rate 0.000100
Timestep 890000
mean reward (100 episodes) -16.430000
best mean reward -16.410000
episodes 721
exploration 0.199000
learning_rate 0.000100
Timestep 900000
mean reward (100 episodes) -16.310000
best mean reward -16.310000
episodes 725
exploration 0.190000
learning_rate 0.000100
[2017-07-19 00:23:31,295] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video000729.mp4
Timestep 910000
mean reward (100 episodes) -16.140000
best mean reward -16.130000
episodes 730
exploration 0.181000
learning_rate 0.000100
Timestep 920000
mean reward (100 episodes) -15.950000
best mean reward -15.950000
episodes 735
exploration 0.172000
learning_rate 0.000100
Timestep 930000
mean reward (100 episodes) -15.660000
best mean reward -15.660000
episodes 739
exploration 0.163000
learning_rate 0.000100
Timestep 940000
mean reward (100 episodes) -15.480000
best mean reward -15.440000
episodes 743
exploration 0.154000
learning_rate 0.000100
Timestep 950000
mean reward (100 episodes) -15.290000
best mean reward -15.290000
episodes 747
exploration 0.145000
learning_rate 0.000100
Timestep 960000
mean reward (100 episodes) -15.060000
best mean reward -15.060000
episodes 750
exploration 0.136000
learning_rate 0.000100
Timestep 970000
mean reward (100 episodes) -14.910000
best mean reward -14.910000
episodes 755
exploration 0.127000
learning_rate 0.000100
Timestep 980000
mean reward (100 episodes) -14.640000
best mean reward -14.640000
episodes 758
exploration 0.118000
learning_rate 0.000100
Timestep 990000
mean reward (100 episodes) -14.530000
best mean reward -14.530000
episodes 762
exploration 0.109000
learning_rate 0.000100
Timestep 1000000
mean reward (100 episodes) -14.160000
best mean reward -14.160000
episodes 766
exploration 0.100000
learning_rate 0.000100
Timestep 1010000
mean reward (100 episodes) -14.030000
best mean reward -14.020000
episodes 770
exploration 0.099775
learning_rate 0.000100
Timestep 1020000
mean reward (100 episodes) -13.940000
best mean reward -13.920000
episodes 775
exploration 0.099550
learning_rate 0.000100
Timestep 1030000
mean reward (100 episodes) -13.610000
best mean reward -13.610000
episodes 779
exploration 0.099325
learning_rate 0.000100
Timestep 1040000
mean reward (100 episodes) -13.340000
best mean reward -13.340000
episodes 783
exploration 0.099100
learning_rate 0.000100
Timestep 1050000
mean reward (100 episodes) -13.130000
best mean reward -13.130000
episodes 786
exploration 0.098875
learning_rate 0.000099
Timestep 1060000
mean reward (100 episodes) -12.880000
best mean reward -12.880000
episodes 789
exploration 0.098650
learning_rate 0.000099
Timestep 1070000
mean reward (100 episodes) -12.610000
best mean reward -12.600000
episodes 794
exploration 0.098425
learning_rate 0.000099
Timestep 1080000
mean reward (100 episodes) -12.390000
best mean reward -12.390000
episodes 798
exploration 0.098200
learning_rate 0.000099
Timestep 1090000
mean reward (100 episodes) -12.050000
best mean reward -12.050000
episodes 802
exploration 0.097975
learning_rate 0.000099
Timestep 1100000
mean reward (100 episodes) -12.180000
best mean reward -12.050000
episodes 806
exploration 0.097750
learning_rate 0.000099
Timestep 1110000
mean reward (100 episodes) -11.910000
best mean reward -11.910000
episodes 809
exploration 0.097525
learning_rate 0.000099
Timestep 1120000
mean reward (100 episodes) -11.650000
best mean reward -11.650000
episodes 813
exploration 0.097300
learning_rate 0.000099
Timestep 1130000
mean reward (100 episodes) -11.310000
best mean reward -11.310000
episodes 817
exploration 0.097075
learning_rate 0.000098
Timestep 1140000
mean reward (100 episodes) -10.970000
best mean reward -10.970000
episodes 821
exploration 0.096850
learning_rate 0.000098
Timestep 1150000
mean reward (100 episodes) -10.710000
best mean reward -10.710000
episodes 824
exploration 0.096625
learning_rate 0.000098
Timestep 1160000
mean reward (100 episodes) -10.400000
best mean reward -10.400000
episodes 827
exploration 0.096400
learning_rate 0.000098
Timestep 1170000
mean reward (100 episodes) -10.070000
best mean reward -10.070000
episodes 830
exploration 0.096175
learning_rate 0.000098
Timestep 1180000
mean reward (100 episodes) -9.700000
best mean reward -9.700000
episodes 833
exploration 0.095950
learning_rate 0.000098
Timestep 1190000
mean reward (100 episodes) -9.270000
best mean reward -9.270000
episodes 836
exploration 0.095725
learning_rate 0.000098
Timestep 1200000
mean reward (100 episodes) -9.150000
best mean reward -9.150000
episodes 839
exploration 0.095500
learning_rate 0.000097
Timestep 1210000
mean reward (100 episodes) -9.030000
best mean reward -9.030000
episodes 842
exploration 0.095275
learning_rate 0.000097
Timestep 1220000
mean reward (100 episodes) -8.750000
best mean reward -8.750000
episodes 845
exploration 0.095050
learning_rate 0.000097
Timestep 1230000
mean reward (100 episodes) -8.560000
best mean reward -8.560000
episodes 848
exploration 0.094825
learning_rate 0.000097
Timestep 1240000
mean reward (100 episodes) -8.340000
best mean reward -8.340000
episodes 851
exploration 0.094600
learning_rate 0.000097
Timestep 1250000
mean reward (100 episodes) -8.060000
best mean reward -8.060000
episodes 854
exploration 0.094375
learning_rate 0.000097
Timestep 1260000
mean reward (100 episodes) -7.930000
best mean reward -7.930000
episodes 857
exploration 0.094150
learning_rate 0.000097
Timestep 1270000
mean reward (100 episodes) -7.580000
best mean reward -7.580000
episodes 860
exploration 0.093925
learning_rate 0.000097
Timestep 1280000
mean reward (100 episodes) -7.250000
best mean reward -7.250000
episodes 863
exploration 0.093700
learning_rate 0.000097
Timestep 1290000
mean reward (100 episodes) -7.020000
best mean reward -7.020000
episodes 866
exploration 0.093475
learning_rate 0.000096
Timestep 1300000
mean reward (100 episodes) -6.840000
best mean reward -6.840000
episodes 869
exploration 0.093250
learning_rate 0.000096
Timestep 1310000
mean reward (100 episodes) -6.630000
best mean reward -6.630000
episodes 872
exploration 0.093025
learning_rate 0.000096
Timestep 1320000
mean reward (100 episodes) -6.180000
best mean reward -6.180000
episodes 875
exploration 0.092800
learning_rate 0.000096
Timestep 1330000
mean reward (100 episodes) -6.080000
best mean reward -6.040000
episodes 878
exploration 0.092575
learning_rate 0.000096
Timestep 1340000
mean reward (100 episodes) -6.100000
best mean reward -6.040000
episodes 881
exploration 0.092350
learning_rate 0.000096
Timestep 1350000
mean reward (100 episodes) -5.980000
best mean reward -5.980000
episodes 884
exploration 0.092125
learning_rate 0.000096
Timestep 1360000
mean reward (100 episodes) -5.770000
best mean reward -5.770000
episodes 887
exploration 0.091900
learning_rate 0.000096
Timestep 1370000
mean reward (100 episodes) -5.660000
best mean reward -5.660000
episodes 890
exploration 0.091675
learning_rate 0.000095
Timestep 1380000
mean reward (100 episodes) -5.450000
best mean reward -5.450000
episodes 893
exploration 0.091450
learning_rate 0.000095
Timestep 1390000
mean reward (100 episodes) -5.020000
best mean reward -5.020000
episodes 896
exploration 0.091225
learning_rate 0.000095
Timestep 1400000
mean reward (100 episodes) -4.840000
best mean reward -4.840000
episodes 898
exploration 0.091000
learning_rate 0.000095
Timestep 1410000
mean reward (100 episodes) -4.650000
best mean reward -4.650000
episodes 901
exploration 0.090775
learning_rate 0.000095
Timestep 1420000
mean reward (100 episodes) -4.260000
best mean reward -4.260000
episodes 904
exploration 0.090550
learning_rate 0.000095
Timestep 1430000
mean reward (100 episodes) -4.010000
best mean reward -3.960000
episodes 907
exploration 0.090325
learning_rate 0.000095
Timestep 1440000
mean reward (100 episodes) -3.860000
best mean reward -3.860000
episodes 911
exploration 0.090100
learning_rate 0.000095
Timestep 1450000
mean reward (100 episodes) -3.670000
best mean reward -3.670000
episodes 914
exploration 0.089875
learning_rate 0.000094
Timestep 1460000
mean reward (100 episodes) -3.540000
best mean reward -3.540000
episodes 916
exploration 0.089650
learning_rate 0.000094
Timestep 1470000
mean reward (100 episodes) -3.350000
best mean reward -3.350000
episodes 919
exploration 0.089425
learning_rate 0.000094
Timestep 1480000
mean reward (100 episodes) -3.150000
best mean reward -3.150000
episodes 922
exploration 0.089200
learning_rate 0.000094
Timestep 1490000
mean reward (100 episodes) -2.970000
best mean reward -2.970000
episodes 925
exploration 0.088975
learning_rate 0.000094
Timestep 1500000
mean reward (100 episodes) -2.960000
best mean reward -2.960000
episodes 928
exploration 0.088750
learning_rate 0.000094
Timestep 1510000
mean reward (100 episodes) -2.710000
best mean reward -2.710000
episodes 932
exploration 0.088525
learning_rate 0.000094
Timestep 1520000
mean reward (100 episodes) -2.640000
best mean reward -2.640000
episodes 934
exploration 0.088300
learning_rate 0.000094
Timestep 1530000
mean reward (100 episodes) -2.710000
best mean reward -2.640000
episodes 938
exploration 0.088075
learning_rate 0.000093
Timestep 1540000
mean reward (100 episodes) -2.420000
best mean reward -2.420000
episodes 941
exploration 0.087850
learning_rate 0.000093
Timestep 1550000
mean reward (100 episodes) -2.250000
best mean reward -2.250000
episodes 944
exploration 0.087625
learning_rate 0.000093
Timestep 1560000
mean reward (100 episodes) -2.110000
best mean reward -2.110000
episodes 947
exploration 0.087400
learning_rate 0.000093
Timestep 1570000
mean reward (100 episodes) -1.870000
best mean reward -1.870000
episodes 950
exploration 0.087175
learning_rate 0.000093
Timestep 1580000
mean reward (100 episodes) -1.570000
best mean reward -1.570000
episodes 953
exploration 0.086950
learning_rate 0.000093
Timestep 1590000
mean reward (100 episodes) -1.330000
best mean reward -1.330000
episodes 956
exploration 0.086725
learning_rate 0.000093
Timestep 1600000
mean reward (100 episodes) -1.080000
best mean reward -1.080000
episodes 959
exploration 0.086500
learning_rate 0.000092
Timestep 1610000
mean reward (100 episodes) -1.070000
best mean reward -1.070000
episodes 962
exploration 0.086275
learning_rate 0.000092
Timestep 1620000
mean reward (100 episodes) -1.010000
best mean reward -1.010000
episodes 965
exploration 0.086050
learning_rate 0.000092
Timestep 1630000
mean reward (100 episodes) -0.890000
best mean reward -0.890000
episodes 969
exploration 0.085825
learning_rate 0.000092
Timestep 1640000
mean reward (100 episodes) -0.680000
best mean reward -0.680000
episodes 972
exploration 0.085600
learning_rate 0.000092
Timestep 1650000
mean reward (100 episodes) -0.540000
best mean reward -0.540000
episodes 975
exploration 0.085375
learning_rate 0.000092
Timestep 1660000
mean reward (100 episodes) -0.390000
best mean reward -0.390000
episodes 978
exploration 0.085150
learning_rate 0.000092
Timestep 1670000
mean reward (100 episodes) -0.010000
best mean reward -0.010000
episodes 981
exploration 0.084925
learning_rate 0.000092
Timestep 1680000
mean reward (100 episodes) 0.150000
best mean reward 0.150000
episodes 984
exploration 0.084700
learning_rate 0.000092
Timestep 1690000
mean reward (100 episodes) 0.460000
best mean reward 0.460000
episodes 987
exploration 0.084475
learning_rate 0.000091
Timestep 1700000
mean reward (100 episodes) 0.500000
best mean reward 0.500000
episodes 990
exploration 0.084250
learning_rate 0.000091
Timestep 1710000
mean reward (100 episodes) 0.780000
best mean reward 0.780000
episodes 993
exploration 0.084025
learning_rate 0.000091
Timestep 1720000
mean reward (100 episodes) 0.790000
best mean reward 0.830000
episodes 996
exploration 0.083800
learning_rate 0.000091
[2017-07-19 02:06:13,794] Starting new video recorder writing to /tmp/hw3_vid_dir2/gym/openaigym.video.0.3025.video001000.mp4
Traceback (most recent call last):
  File "/home/yongzhao/Desktop/homework-master/hw3/run_dqn_atari.py", line 133, in <module>
    main()
  File "/home/yongzhao/Desktop/homework-master/hw3/run_dqn_atari.py", line 130, in main
    atari_learn(env, session, num_timesteps=task.max_timesteps)
  File "/home/yongzhao/Desktop/homework-master/hw3/run_dqn_atari.py", line 77, in atari_learn
    grad_norm_clipping=10
  File "/home/yongzhao/Desktop/homework-master/hw3/dqn.py", line 233, in learn
    obs = env.reset()
  File "/home/yongzhao/Downloads/gym-master/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/yongzhao/Downloads/gym-master/gym/core.py", line 283, in _reset
    return self.env.reset()
  File "/home/yongzhao/Downloads/gym-master/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/yongzhao/Desktop/homework-master/hw3/atari_wrappers.py", line 124, in _reset
    return _process_frame84(self.env.reset())
  File "/home/yongzhao/Downloads/gym-master/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/yongzhao/Desktop/homework-master/hw3/atari_wrappers.py", line 33, in _reset
    self.env.reset()
  File "/home/yongzhao/Downloads/gym-master/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/yongzhao/Desktop/homework-master/hw3/atari_wrappers.py", line 102, in _reset
    obs = self.env.reset()
  File "/home/yongzhao/Downloads/gym-master/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/yongzhao/Desktop/homework-master/hw3/atari_wrappers.py", line 19, in _reset
    self.env.reset()
  File "/home/yongzhao/Downloads/gym-master/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/yongzhao/Desktop/homework-master/hw3/atari_wrappers.py", line 68, in _reset
    obs = self.env.reset()
  File "/home/yongzhao/Downloads/gym-master/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/yongzhao/Downloads/gym-master/gym/wrappers/monitoring.py", line 41, in _reset
    self._after_reset(observation)
  File "/home/yongzhao/Downloads/gym-master/gym/wrappers/monitoring.py", line 198, in _after_reset
    self._reset_video_recorder()
  File "/home/yongzhao/Downloads/gym-master/gym/wrappers/monitoring.py", line 219, in _reset_video_recorder
    self.video_recorder.capture_frame()
  File "/home/yongzhao/Downloads/gym-master/gym/monitoring/video_recorder.py", line 121, in capture_frame
    self._encode_image_frame(frame)
  File "/home/yongzhao/Downloads/gym-master/gym/monitoring/video_recorder.py", line 167, in _encode_image_frame
    self.encoder = ImageEncoder(self.path, frame.shape, self.frames_per_sec)
  File "/home/yongzhao/Downloads/gym-master/gym/monitoring/video_recorder.py", line 261, in __init__
    self.start()
  File "/home/yongzhao/Downloads/gym-master/gym/monitoring/video_recorder.py", line 293, in start
    self.proc = subprocess.Popen(self.cmdline, stdin=subprocess.PIPE, preexec_fn=os.setsid)
  File "/home/yongzhao/anaconda2/lib/python2.7/subprocess.py", line 390, in __init__
    errread, errwrite)
  File "/home/yongzhao/anaconda2/lib/python2.7/subprocess.py", line 916, in _execute_child
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
[2017-07-19 02:06:13,895] Finished writing results. You can upload them to the scoreboard via gym.upload('/tmp/hw3_vid_dir2/gym')
yongzhao@yongzhao-Lenovo-ideapad-Y700-15ISK:~$ 

